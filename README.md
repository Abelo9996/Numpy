# numc

Here's what I did in project 4:
Having just finished my extensive testing and optimizing of the code, Project 4 was certainly a challenge that was hard to overcome even though I had begun the project 3 weeks before its due date. Having finished it, I have fully implemented a correct version of numc along with performance speedups that pass the required thresholds for all tests other than pow (x1495, I'll speak on that later below).

Regarding task 1, I believe that this was a quite simple task where we just really needed to have knowledge from the first 2 weeks of the course to fully complete all of the functions needed to implement within our code. Having not thought of an optimal solution from the beginning of the project, I initially began implementing approaches that were quite inefficient, where I had used triple for loops to solve some of the tasks (not good). Although I had initially approached the allocation format in a 2D way, where I had double pointers pointing to every single row for which they would point (single pointers) to the columns of the matrix. Although initially an easy approach, I later decided to swap to a new format that stores matrices in ultimately a 1D format, where all columns are within a single pointer, and the rows point towards the start of a certain row. With this approach, my performance increased drastically (although more on that later).  Going back to what I was talking about, my approaches to the add, sub, mul, and pow functions were just inefficient triple for loops that took values from the i and j row and column respectively, then doing the action that was needed (along with that, I used many if statements that also decreased speedups on the hive). I approached the deallocate and allocate_matrix_ref in the exact approach to the spec ( along with the understanding of allocate), and then I handled every single possible error that may arise from each function call. and returned it with a -1 value to indicate that an error had occurred. Other than that, my set/get functions were pretty straightforward and needed no changes throughout the development of the projects, since we just needed to get the certain row and column, and do what needed to be done.

Regarding task 2, it needed just a quick understanding of setting up a library using the C-Python context of the interface, which really required a solid 30 minutes for me to understand, for which setting up took around 5-10 minutes to do (along with the descriptions, modules, flags, extension libraries, etc). After having done that, I was fully set to move on to task 3.

Regarding task 3, there were certainly tough parts to doing it and really needed a lot to understand of the C-Python context and how it would apply to the dumbpy module that we had been given for reference. Although the first few functions were easy to setup (such as add, mul, pow, neg,abs, sub,get,set), it needed a bit to understand how the C-Python checks are done among the code, for which I would have to also deal with errors and how I would require to handle them, along with which type of error to throw. In addition to this, I also needed a bit of time to understand how Matrix61c_as_number and Matrix61c_methods[] on the given website at https://docs.python.org/3.6/c-api/structures.html, however, that again also took around 20-ish minutes to understand and fully implement on to the code. The instance methods subpart was also quite easy to understand and quite simple to implement, however, I took some extra time to fully make sure that all of the errors being thrown from the code whenever incorrect arguments are typed in are functioning correctly. Now, for the big boy, indexing methods (tun-tun-tuuuuuuuuuuun!).  By far being one of the hardest things to implement within the codes of the project, I really just needed a whiteboard that would break down every single case of input into many if statements, and then using the C-Python syntax to correctly do the task and check for errors. Some of the challenges within the indexing part was to really understand how slices work and how I would need to use Py_ssize_t along with PySlice_GetIndicesEx to get the relevant information needed to access the index values of the indices that would need to be read/overwritten. After having fully solidified my understanding of these things with the HUUUUUGE help from the staff and other students on Piazza, I was able to begin my implementation and the super tedious work of implementing these indexing instances to the code, and also manipulating the entered matrices with the new values. After finishing task 3, I took some time to revisit every single line of code and see if everything has been entered correctly, however, I could not extensively test my code using the numc library due to the fact that my computer would just not accept my "import numc as nc", so I needed some help from Jie to fix that issue (thanks Jie!).

Now, onto the last and personally most interesting task of the project, SPEEDUP! This task really required me to understand what types of approaches really make the functions work correctly and as efficiently as possible, for which I had to resort to the lectures to fully understand how everything worked. After having spent a while trying to understand the best approach, I went ahead and began my approaches to the simpler functions within the matrix.c file. So first of all, since the set/get functions were really a single line of code, they didn't really need any optimization done to them, so I left them as it is. But, as I had previously mentioned, staff and students on Piazza were really encouraging other students/peers to use the 1D matrix approach to get the best speedups possible (which completely makes sense, since accessing a single array to find an element would lead to a much quicker operation time than having to iterate through a double pointer, finding the single pointer, and then iterating through that to find the column value. So after having shifted my approach to the 1D format, I began with add/sub/neg/abs/fill. All of these functions really shared the same general format, for which I needed to "flatten" out the double for loops in my code to a single for loop (which was why a 1D matrix was really helpful). Lab 9 was really helpful for approaching these functions (and the ones below), for which I mainly just needed the SSE approach to optimize my code (along with defining "#pragma omp parallel for" at the beginning of the for loops needed). After having done this, my simple test functions had achieved a speedup of x4.98, which is juuuuuust above the threshold. Onto the last two and pretty much the hardest optimizations needed for a function, multiply and pow. For multiply, I approached the optimization techniques using the SSE intrinsics along with pragma similarly to the simple functions, however, I decided to iterate using 4 rows that applied the values for each specific value of each row with triple loops, this caused a speedup of x205, which is way more than the required threshold for mul at x95. Although this looks promising, my pow function has disappointed with the fact that the speedup is around x1495 (if I have changed these sentences, then it means that I somehow made my code better, if you see this, then I couldn't fix it sadly :( ). For pow, I added a method of repetitive squaring for which I included temporary matrices that held the results of matrices to a certain power (such as the identity matrix, the mat matrix, and the result of squaring mat), and then I used these matrices to carry on forward with the next power multiplication by bit manipulating the power value by logically shifting to the right by 1. After having done this, I finished my entire project, although now my speedup is at x1495 and is the only thing that fails on the visible tests so far. 

Thank you staff! Have a great day ahead :)
